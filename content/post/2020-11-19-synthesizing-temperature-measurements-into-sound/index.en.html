---
title: 'The Chaos Machine - Synthesizing Temperature Measurements into Sound '
author: Urs Wilke
date: '2020-11-19'
slug: []
categories: []
tags:
  - midi
  - rstats
  - reticulate
  - ggplot
  - python
  - arduino
  - fluidsynth
subtitle: ''
summary: ''
authors: []
lastmod: '2020-11-19T14:31:07+01:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: true
projects: []
---

<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/viz/viz.js"></script>
<link href="/rmarkdown-libs/DiagrammeR-styles/styles.css" rel="stylesheet" />
<script src="/rmarkdown-libs/grViz-binding/grViz.js"></script>
<script src="/rmarkdown-libs/pymjs/pym.v1.min.js"></script>
<link href="/rmarkdown-libs/vembedr/css/vembedr.css" rel="stylesheet" />


<div id="tldr" class="section level2">
<h2>tl;dr</h2>
<p>Want to learn something about arduino, midi audio or sound synthesis? Using
python, R and many other tools. Or you just
have some spare minutes to watch and listen to and read about a project where
live data is translated to sound. This article shows how the <a href="https://gitlab.com/urswilke/chaos_machine_code">Chaos
Machine</a> produces sound like
this:</p>
<audio controls="">
<source src="live_record.mp3" type="audio/mp3"/>
</audio>
</div>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>This is an introductory blog post with a strong focus on documentation and some
of the relevant topics if you want to construct such a machine. The cool thing
is that all the software used is free. The only money spent was on the hardware
(a circuit of a microcontroller and some thermometers), which is not very
expensive. All the software (microcontroller, programming, data management and
audio-related) is completely free. Furthermore, all the code used in this project
is open source.</p>
<p>I will give an overview over the <a href="https://gitlab.com/urswilke/chaos_machine_code">Chaos
Machine</a> code repository. This
repository is the result of the artist and my friend Axel Crettenand having the
idea of his project called CHOEUR AQUATIQUE (the <em>Underwater Choir</em>) and hiring
me to develop the code.</p>
<p>As we live in different cities and traveling is difficult due to Covid-19 we
decided itâ€™s best to make a public repository with the instructions for Axel to
reconstruct the machine himself. And with the possibility that somebody else is
interested I was more motivated to write a good documentation. :) This article
is to briefly introduce you to the project.</p>
<p>To get an idea how the machine sounds so far you can have a listen to the
generated mp3 file in this
<a href="https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/python/recorded_data">folder</a>
(or scroll down to the audio player at the bottom of this article). This file is
the synthesization of the midi file you can also find there.</p>
</div>
<div id="technical-description-of-the-chaos-machine" class="section level2">
<h2>Technical description of the chaos machine</h2>
<p>Basically, the machine translates temperature measurements into sound in real
time. The <a href="https://gitlab.com/urswilke/chaos_machine_code/-/blob/master/arduino/send_temp/send_temp.ino">arduino code
sketch</a>
uploaded to the microcontroller reads the measured temperatures of multiple
thermometers and then sends them to the computer. On the PC a python program
(see
<a href="https://gitlab.com/urswilke/chaos_machine_code/-/blob/master/python/temperatures_to_midi.ipynb">here</a>)
runs a main loop where the sent temperature data is again read in. The
temperature differences are then translated into midi notes of a chosen scale. The
midi nodes are then sent to fluidsynth which finally synthesizes the midi notes
to sound. This will be referred to as the <em>chaos machine</em>.</p>
<div id="main-steps-in-the-chaos-machine" class="section level3">
<h3>Main steps in the chaos machine</h3>
<p>This is an interactive diagram<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<ul>
<li>hover (mouse-over) to see description</li>
<li>click on clickable nodes (not all) to view source code file</li>
</ul>
<div id="htmlwidget-1" style="width:672px;height:480px;" class="grViz html-widget"></div>
<script>HTMLWidgets.pymChild = new pym.Child();HTMLWidgets.addPostRenderHandler(function(){
                                setTimeout(function(){HTMLWidgets.pymChild.sendHeight();},100);
                            });</script>
<script type="application/json" data-for="htmlwidget-1">{"x":{"diagram":"#  do not edit by hand. This file is auto generated by when knitting work_flow.Rmd.\ndigraph workflow {\n  ranksep=.5;\n  graph [\n    truecolor=true,\n    # the last 2 \"00\" make it completely transparent here, \n    # thus all that comes before - I don\"t care\n    bgcolor=\"#ffffff00\",\n    fontname = \"helvetica\",\n    #splines=ortho,\n    concentrate=true\n  ];\n  node [\n    fontname = \"helvetica\", \n    style = \"rounded,filled,radial\", \n    gradientangle=60, \n    fillcolor=\"#dddddd99:#7777772f\", \n    # gradients dont work on observable...:\n    # fillcolor=\"#dddddd99\", \n    fontsize=25,\n    penwidth=4, \n    color = \"#ffffff55\",\n    width = 2.5\n  ];\n  edge [\n    fontname = \"helvetica\", \n    penwidth=5, \n    color=\"#aaaaaabb\"\n  ];\n  penwidth=5;\n  style=rounded\n\n  subgraph cluster_arduino {\n    label = < <B>arduino<\/B> >;\n    bgcolor = \"#a8feff\";\n    color = \"#3e979d\";\n    fontcolor = \"#3e979d\";\n    fontsize = 30;\n    Thermometers -> mc;\n    sketch -> mc;\n    Thermometers [shape=box];\n    sketch [\n      label = \"send_temp.ino\", \n      shape=box, \n      URL=\"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/arduino/send_temp/send_temp.ino\", \n      tooltip = \"arduino sketch to read multiple DS18B20 thermometers and then print the information to the serial connection\"\n    ];\n    {rank=same; mc; sketch}\n  }\n  sc -> python [\n    weight = 100, \n    tooltip = \"setup serial connection in arduino\",\n    URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/python/T_to_midi.ipynb#Arduino\"\n  ]\n\n  subgraph cluster_main {\n    label = < <B>python<\/B> >;\n    bgcolor = \"#fffb4b\";\n    color = \"#4f93ba\";\n    fontcolor = \"#4f93ba\";\n    fontsize = 30;\n    penwidth=5;\n    #graph[style=dotted];\n    \"functions.py\" [\n      shape=box, \n      tooltip = \"functions that are imported in the T_to_midi notebook\",\n      URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/python/functions.py\"\n    ]\n    python [\n      shape=box, \n      tooltip = \"python real-time loop to\n* read serial string, extract temperatures\n* calculate temperature differences\n* translate differences to midi notes according to a specified musical scale\n* send the note events to a midi port in real time \nDuring the loop the data is recorded in lists and when it has finished the data is written to a midi and csv files. \", \n      label = \"T_to_midi.ipynb\",\n      URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/python/T_to_midi.ipynb\"\n    ];\n    \"functions.py\" -> python\n    mc [\n      shape=box, \n      label=\"micro-controller\",\n      tooltip=\"the micro-controller is connected to the PC via USB\",\n    ];\n    {rank = same; \"functions.py\" python}\n  }\n  \n#  subgraph cluster_main_to_R_connectors {\n#    label = \"main workflow\";\n\n\n#  }\n  subgraph cluster_fluidsynth {\n    label = <<B>fluidsynth  <\/B>>;\n    fontsize = 30;\n    bgcolor = \"#ffd030\";\n    color = \"#f07531\";\n    fontcolor = \"#f07531\";\n    penwidth=5;\n    sf2 [shape = cylinder, label = \"sound\\nfont\"];\n    fluidsynth [\n      shape=box,\n      tooltip = \"* Fluidsynth can be easily started via the GUI QSynth.\\n* An sf2 soundfont file has to be used.\\n* A midi port can be synthesized in real time, or\\n* A midi file can be rendered to an audio file.\"\n    ];\n    sf2 -> fluidsynth;\n    {rank=same; fluidsynth sf2}\n  }\n  \n  \n  mp -> fluidsynth [ weight = 100]\n  mc -> sc [\n    arrowhead=none, \n    tooltip = \"setup serial connection in arduino\",\n    URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/arduino/send_temp/send_temp.ino#L24\"\n  ];\n  python -> mp [arrowhead=none, weight = 1000];\n  sc [\n    label=\"serial\\nconnection\", \n    color=grey, \n    shape=diamond,\n    tooltip = \"The serial string sent from the arduino is of the following format:\nS: 1, ID: 40255662332332138251, T: 23.50; S: 2, ID: 402552102282332138209, T: 23.50; S: 3, ID: 402551932392332138119, T: 23.75; S: 4, ID: 4025514153413227192, T: 22.75; S: 5, ID: 402552272422332138169, T: 22.62\",\n    URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/python/recorded_data/serial_string.txt\"\n  ];\n  mp [\n    label = \"midi\\nport\", \n    shape=diamond, \n    color=grey,\n    tooltip = \"The midi port to fluidsynth is set up by the python code in T_to_midi.ipynb\",\n    URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/python/T_to_midi.ipynb#Setup_fluidsynth_connection\"\n  ];\n  #mc -> sc -> python -> mp -> fluidsynth[ style = invis, weight= 10 ];\n  fluidsynth -> speakers\n  \n  subgraph cluster_speaker {\n    label = < <B>speaker<\/B> >;\n    fontsize = 30;\n    bgcolor=\"#FFD700:#CCA600\";\n    # gradients dont work on observable...:\n    # bgcolor=\"#CCA600\";\n    speakers [label=\"ðŸ”ŠðŸŽ¶\"];\n  }\n  \n\n  \n  \n  # mc -> sc [ weight = 100, style=invis]\n  # python -> mp [ weight = 100, style=invis]\n  # mp -> fluidsynth [ weight = 100, style=invis]\n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
<p>The main interfaces are the serial connection between python and the arduino on the one hand. On the other hand, the midi format can either be synthesized directly with a midi port or by rendering the midi to audio files. This is done by fluidsynth using an sf2 soundfont that stores audio information for midi notes.</p>
</div>
<div id="bigger-picture" class="section level3">
<h3>Bigger picture</h3>
<p>Watch here if youâ€™re interested in a deeper understanding of the available tools
in the project and arduino / midi in general.</p>
<p>The execution of the code produces output files. These are then processed for
visualization of the notes and audio file output. Furthermore, there are some
auxiliary functions. The following diagram depicts how these programs can be
used and how the elements roughly interact with each other.</p>
<div id="htmlwidget-2" style="width:672px;height:480px;" class="grViz html-widget"></div>
<script>HTMLWidgets.pymChild = new pym.Child();HTMLWidgets.addPostRenderHandler(function(){
                                setTimeout(function(){HTMLWidgets.pymChild.sendHeight();},100);
                            });</script>
<script type="application/json" data-for="htmlwidget-2">{"x":{"diagram":"#  do not edit by hand. This file is auto generated by when knitting work_flow.Rmd.\ndigraph workflow {\n  ranksep=.5;\n  graph [\n    truecolor=true,\n    # the last 2 \"00\" make it completely transparent here, \n    # thus all that comes before - I don\"t care\n    bgcolor=\"#ffffff00\",\n    fontname = \"helvetica\",\n    #splines=ortho,\n    concentrate=true\n  ];\n  node [\n    fontname = \"helvetica\", \n    style = \"rounded,filled,radial\", \n    gradientangle=60, \n    fillcolor=\"#dddddd99:#7777772f\", \n    # gradients dont work on observable...:\n    # fillcolor=\"#dddddd99\", \n    fontsize=25,\n    penwidth=4, \n    color = \"#ffffff55\",\n    \n  ];\n  edge [\n    fontname = \"helvetica\", \n    penwidth=5, \n    color=\"#aaaaaabb\"\n  ];\n  penwidth=5;\n  style=rounded\n\n  subgraph cluster_arduino {\n    label = < <B>arduino<\/B> >;\n    bgcolor = \"#a8feff\";\n    color = \"#3e979d\";\n    fontcolor = \"#3e979d\";\n    fontsize = 30;\n    Thermometers -> mc;\n    sketch -> mc;\n    Thermometers [shape=box];\n    sketch [\n      label = \"send_temp.ino\", \n      shape=box, \n      URL=\"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/arduino/send_temp/send_temp.ino\", \n      tooltip = \"arduino sketch to read multiple DS18B20 thermometers and then print the information to the serial connection\"\n    ];\n    {rank=same; mc; sketch}\n  }\n  sc -> python [\n    weight = 100, \n    tooltip = \"setup serial connection in arduino\",\n    URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/python/T_to_midi.ipynb#Arduino\"\n  ]\n\n  subgraph cluster_main {\n    label = < <B>python<\/B> >;\n    bgcolor = \"#fffb4b\";\n    color = \"#4f93ba\";\n    fontcolor = \"#4f93ba\";\n    fontsize = 30;\n    penwidth=5;\n    #graph[style=dotted];\n    \"functions.py\" [\n      shape=box, \n      tooltip = \"functions that are imported in the T_to_midi notebook\",\n      URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/python/functions.py\"\n    ]\n    python [\n      shape=box, \n      tooltip = \"python real-time loop to\n* read serial string, extract temperatures\n* calculate temperature differences\n* translate differences to midi notes according to a specified musical scale\n* send the note events to a midi port in real time \nDuring the loop the data is recorded in lists and when it has finished the data is written to a midi and csv files. \", \n      label = \"T_to_midi.ipynb\",\n      URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/python/T_to_midi.ipynb\"\n    ];\n    \"functions.py\" -> python\n    mc [\n      shape=box, \n      label=\"micro-controller\",\n      tooltip=\"the micro-controller is connected to the PC via USB\",\n    ];\n    {rank = same; \"functions.py\" python}\n  }\n  \n#  subgraph cluster_main_to_R_connectors {\n#    label = \"main workflow\";\n\n\n#  }\n  subgraph cluster_fluidsynth {\n    label = <<B>fluidsynth  <\/B>>;\n    fontsize = 30;\n    bgcolor = \"#ffd030\";\n    color = \"#f07531\";\n    fontcolor = \"#f07531\";\n    penwidth=5;\n    sf2 [shape = cylinder, label = \"sound\\nfont\"];\n    fluidsynth [\n      shape=box,\n      tooltip = \"* Fluidsynth can be easily started via the GUI QSynth.\\n* An sf2 soundfont file has to be used.\\n* A midi port can be synthesized in real time, or\\n* A midi file can be rendered to an audio file.\"\n    ];\n    sf2 -> fluidsynth;\n    {rank=same; fluidsynth sf2}\n  }\n  subgraph cluster_output_files {\n  label = < <B>output files<\/B> >;\n  fontsize = 30;\n  bgcolor = \"#ffd080\" \n  color = \"#b25605\" \n  fontcolor = \"#b25605\" \n  midifile [\n    shape = cylinder,\n    label = \"live_record.mid\",\n    tooltip = \"midi file written by T_to_midi.ipynb\",\n    URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/python/recorded_data/\"\n  ];\n  prelim_mp3 [\n    label = \"test.mp3\"\n    shape = cylinder;\n    tooltip = \"resulting mp3 file, when the midifile test.mid is rendered by fluidsynth with the specified soundfont\",\n    URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/R/preliminary_study/\"\n  ];\n  mp3 [\n    label = \"live_record.mp3\"\n    shape = cylinder;\n    tooltip = \"resulting mp3 file, when the midifile live_record.mid (written by T_to_midi.ipynb) is rendered by fluidsynth with the specified soundfont\"\n    URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/python/recorded_data/\"\n  ];\n  csv [shape = cylinder];\n  prelim_audio [\n    shape=cylinder, \n    label=\"test.mid\",\n    tooltip = \"midi file written by preliminary_study.Rmd\",\n    URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/R/preliminary_study/\"\n  ]\n  prelim_audio -> prelim_mp3\n  midifile -> mp3\n\n\n  {rank=same;prelim_audio, midifile}\n}\npython -> csv [color = \"#4f93ba\"];\npython -> midifile [color = \"#4f93ba\"];\nfluidsynth -> mp3 [style = dashed, color = \"#f07531\"]\nfluidsynth -> prelim_mp3 [style = dashed, color = \"#f07531\"]\n\n  \n  mp -> fluidsynth [ weight = 100]\n  mc -> sc [\n    arrowhead=none, \n    tooltip = \"setup serial connection in arduino\",\n    URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/arduino/send_temp/send_temp.ino#L24\"\n  ];\n  python -> mp [arrowhead=none, weight = 1000];\n  sc [\n    label=\"serial\\nconnection\", \n    color=grey, \n    shape=diamond,\n    tooltip = \"The serial string sent from the arduino is of the following format:\nS: 1, ID: 40255662332332138251, T: 23.50; S: 2, ID: 402552102282332138209, T: 23.50; S: 3, ID: 402551932392332138119, T: 23.75; S: 4, ID: 4025514153413227192, T: 22.75; S: 5, ID: 402552272422332138169, T: 22.62\",\n    URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/python/recorded_data/serial_string.txt\"\n  ];\n  mp [\n    label = \"midi\\nport\", \n    shape=diamond, \n    color=grey,\n    tooltip = \"The midi port to fluidsynth is set up by the python code in T_to_midi.ipynb\",\n    URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/python/T_to_midi.ipynb#Setup_fluidsynth_connection\"\n  ];\n  #mc -> sc -> python -> mp -> fluidsynth[ style = invis, weight= 10 ];\n  fluidsynth -> speakers\n  \n  subgraph cluster_speaker {\n    label = < <B>speaker<\/B> >;\n    fontsize = 30;\n    bgcolor=\"#FFD700:#CCA600\";\n    # gradients dont work on observable...:\n    # bgcolor=\"#CCA600\";\n    speakers [label=\"ðŸ”ŠðŸŽ¶\"];\n  }\n  \n\n  subgraph cluster_R {\n  # https://stackoverflow.com/questions/6824431/placing-clusters-on-the-same-rank-in-graphviz\n  label = < <B>R<\/B> >;\n  fontsize = 30;\n  bgcolor = \"#87d5ff\"\n  color = \"#217ca3\"\n  fontcolor = \"#217ca3\"\n  newrank=true;\n  csv -> \"plot_csv_data.R\";\n  \"plot_midifile.Rmd\" [\n    shape=box, \n    URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/R/plot_midifile/plot_midifile.md\"\n    tooltip = \"In this document, a piano roll visualization is produced of the midifile written at the end of the python notebook. And I will promote the two packages I wrote:\n* The python package [miditapyr](https://github.com/urswilke/miditapyr/) can tabulate midifile data (read in by [mido](github.com/mido/mido)) in dataframes.\n* The R package [pyramidi](https://github.com/urswilke/pyramidi/) can transform these dataframes to a wide format that allows for an easy way to plot piano roll plots.\"\n  ]\n  \"plot_csv_data.R\" [\n    shape=box, \n    tooltip = \"plot the data in the csv files written in python/T_to_midi.ipynb\"\n    URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/R/plot_csv_data/plot_csv_data.md\"\n  ]\n  plotter [\n    label = \"live_plotter.R\",\n    shape=box, \n    tooltip = \"script to plot the serial data in real time\",\n    URL = \"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/R/live_plotter/live_plotter.R\"\n  ]\n  #&#8226; after the real-time loop, csv, midi and mp3 files are generated<br ALIGN = \"LEFT\"/>\n  prelim [\n    shape=box, \n    label=\"preliminary_study.Rmd\", \n    URL=\"https://gitlab.com/urswilke/chaos_machine_code/-/tree/master/R/preliminary_study/preliminary_study.md\"\n    tooltip=\"This is a preliminary study to translate temperature measurements into sound. \n* Fake temperaure curves are generated\n* pairwise differences are calculated\n* these differnces are mapped to midi notes \n* this information is saved to a midi file\n* which is synthesized to an audiofile\"\n  ];\n  #  {rank=same; midifile [group = g3] csv [group = g3] }\n  edge[style=invis];\n  python -> plotter;\n  plotter -> prelim;\n  prelim -> \"plot_midifile.Rmd\";\n  \"plot_midifile.Rmd\" -> \"plot_csv_data.R\";\n  \"plot_midifile.Rmd\" -> \"plot_csv_data.R\";\n}\n\n{rank=same; python plotter}\n#{rank=same; prelim prelim_audio}\nsc -> plotter;\nmidifile -> \"plot_midifile.Rmd\"\n  \nprelim -> prelim_audio\nedge[style=invis];\nmidifile -> csv;\n\n\n  \n  # mc -> sc [ weight = 100, style=invis]\n  # python -> mp [ weight = 100, style=invis]\n  # mp -> fluidsynth [ weight = 100, style=invis]\n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<div id="further-short-descriptions" class="section level2">
<h2>Further short descriptions</h2>
<div id="live-plotter" class="section level3">
<h3>Live plotter</h3>
<p>Perhaps itâ€™s best to start with the data sent by the microcontroller. Itâ€™s
really easy to program a <a href="https://gitlab.com/urswilke/chaos_machine_code/-/blob/master/R/live_plotter/live_plotter.R">live plotter in
R</a>
with the package <a href="https://github.com/r-arduino/arduinor">arduinor</a>. This yields
an app shown here:</p>
<div class="vembedr">
<div>
<iframe src="https://www.youtube.com/embed/BN-RWrFkblc" width="533" height="300" frameborder="0" allowfullscreen=""></iframe>
</div>
</div>
<p>showing how I touched 4 of the 5 thermometers briefly after starting the measurements.</p>
</div>
<div id="temperatures-to-midi" class="section level3">
<h3>Temperatures to midi</h3>
<div id="translation-scheme" class="section level4">
<h4>Translation scheme</h4>
<p>Once the temperatures are measured and sent to the PC, python computes all the
pairwise differences Î” and translates them to midi notes in a given scale. For the
C major scale this yields</p>
<p><img src="T_to_midi_Cmaj.svg" /><!-- --></p>
<p>where the function maps to the midi notes of the white piano keys. This is
explained in more detail
<a href="https://gitlab.com/urswilke/chaos_machine_code/-/blob/master/R/midi_intro/midi_intro.md">here</a>.</p>
</div>
<div id="chaos-machine-data" class="section level4">
<h4>Chaos machine data</h4>
<p>To get an idea how the translation scheme works, have a look at this plot:</p>
<p><img src="csv_vis.svg" /><!-- --></p>
<p>It shows the live data that is generated during the main loop of the chaos machine. The differences
<code>Î”</code> of the temperatures <code>T</code> received from the microcontroller are
transformed to <code>midi</code> notes according to the above scheme.
The data for the plot is produced during the execution of the chaos machine and saved to csv files after
it has finished. Only look into these csv files if youâ€™re interested in
more detail what kind of data structures are used to control the machine. If you
want to try out the machine, have a look at the <a href="https://gitlab.com/urswilke/chaosmachine">chaos machine
package</a><a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>.</p>
</div>
</div>
<div id="midi-to-audio-live" class="section level3">
<h3>Midi to audio (live)</h3>
<p>Once the midi notes are sent, they can be synthesized to audio with fluidsynth
and a soundfont file. The soundfont specifies which sample is played for which
midi note. An example how to do that with python can be seen
<a href="https://gitlab.com/urswilke/chaos_machine_code/-/blob/master/python/play_soundfont/play_soundfont.ipynb">here</a>.
This yields in a sequence of rising notes of the sound font.
<a href="https://musical-artifacts.com/artifacts/387">This</a> soundfont of choir voices
was used. You can enjoy the result in the following audio file:</p>
<audio controls="">
<source src="increasing_sequence.mp3" type="audio/mp3"/>
</audio>
<p>Consider this as a minimal example how to send live midi data with python to
fluidsynth and after the session translate the recorded live data to a midi file
and render it to the audio file that you were about to listen.</p>
</div>
<div id="output-files" class="section level3">
<h3>Output files</h3>
<p>The main python programm produces</p>
<ul>
<li>csv output files (as already mentioned) of
<ul>
<li>the temperatures from the serial connection</li>
<li>the calculated temperature differences</li>
<li>the derived midi notes, as well as</li>
</ul></li>
<li>a midi file
<ul>
<li>which is then transformed to audio files by fluidsynth using the specified sf2 soundfont</li>
<li>a musescore sheet music file</li>
</ul></li>
</ul>
</div>
<div id="midi-files" class="section level3">
<h3>Midi files</h3>
<p>The piano roll visualizations of the midi notes can also be derived from the
midi file thatâ€™s generated after the chaos machine has finished. In the algorithm a new
note is only started (o) if it differs from the previous note, otherwise the
previous is not stopped (+).</p>
<p><img src="midi_piano_roll.svg" /><!-- --></p>
<div id="midi-files-to-audio-files" class="section level4">
<h4>Midi files to audio files</h4>
<p>The midi files can be rendered to audio files also using fluidsynth and a soundfont.</p>
<p>You can listen to the result here:</p>
<audio controls="">
<source src="live_record.mp3" type="audio/mp3"/>
</audio>
</div>
<div id="musescore" class="section level4">
<h4>Musescore</h4>
<p><a href="https://musescore.org/">Musescore</a> is a music notation software. The midi file
can be automatically translated to sheet music in the musescore mscz file format by
running</p>
<pre class="bash"><code>mscore3 live_record.mid -o output_file.mscz</code></pre>
<p>The mscz file can then be animated to this
<a href="https://www.youtube.com/watch?v=XNDlgnyYGto">beauty</a><a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>. The sound in this video was generated with their proper
soundfont. Channel 10 is traditionally used for <a href="https://fedoraproject.org/wiki/User:Crantila/FSC/Synthesizers/FluidSynth#Assigning_Programs_to_Channels_with_Qsynth">percussion</a>. :)</p>
<!-- As can be seen in the notes sheet, quantization of the notes' times the notes could prevent  -->
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>If youâ€™re interested how you can produce and
manipulate graphs like this with <a href="https://graphviz.org/">graphviz</a> code try out
yourself with the interactive ObservableHQ notebook
<a href="https://observablehq.com/@urswilke/workflow-of-the-chaos-machine-project">HERE</a>.<a href="#fnref1" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn2"><p>The package also provides a
<a href="https://gitlab.com/urswilke/chaosmachine#demo-mode">demo mode</a> option. Thus, you can try it out without having the microcontroller
setup but instead using recorded temperature data also provided by the package.<a href="#fnref2" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn3"><p>Also checkout the
animation of the midi data on the
<a href="https://musescore.com/user/36624930/scores/6458979">musescore</a> webpage by
clicking play (make sure to also choose the funky piano roll animation by clicking on
the piano key symbol!)<a href="#fnref3" class="footnote-back">â†©ï¸Ž</a></p></li>
</ol>
</div>
